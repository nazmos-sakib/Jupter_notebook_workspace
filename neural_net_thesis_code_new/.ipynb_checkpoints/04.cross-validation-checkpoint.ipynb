{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import all necessary liberty\n",
    "\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "#from sklearn.utils import shuffle\n",
    "import csv\n",
    "\n",
    "#spliting dataset into traning set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "#missing value handle\n",
    "from sklearn.preprocessing import Imputer\n",
    "#To shuffle the data set\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv('data.tab', sep='\\t')\n",
    "\n",
    "len(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>1.0.1</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>1.0.2</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>0.0.5</th>\n",
       "      <th>1.0.3</th>\n",
       "      <th>0.0.6</th>\n",
       "      <th>0.0.7</th>\n",
       "      <th>0.0.8</th>\n",
       "      <th>0.0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   50.0  1.0  0.0  0.0.1  0.0.2  1.0.1  0.0.3  1.0.2  0.0.4  0.0.5  1.0.3  \\\n",
       "0  55.0  1.0  1.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    1.0   \n",
       "1  47.0  1.0  0.0    1.0    1.0    0.0    1.0    1.0    1.0    0.0    0.0   \n",
       "\n",
       "   0.0.6  0.0.7  0.0.8  0.0.9  \n",
       "0    0.0    0.0    1.0    1.0  \n",
       "1    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suffle the data set\n",
    "#np.random.seed(40)\n",
    "df = data_frame.reindex(np.random.permutation(data_frame.index))\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_set[:,:14]\n",
    "Y = data_set[:,14:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>1.0.1</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>1.0.2</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>0.0.5</th>\n",
       "      <th>1.0.3</th>\n",
       "      <th>0.0.6</th>\n",
       "      <th>0.0.7</th>\n",
       "      <th>0.0.8</th>\n",
       "      <th>0.0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   50.0  1.0  0.0  0.0.1  0.0.2  1.0.1  0.0.3  1.0.2  0.0.4  0.0.5  1.0.3  \\\n",
       "0  55.0  1.0  1.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    1.0   \n",
       "1  47.0  1.0  0.0    1.0    1.0    0.0    1.0    1.0    1.0    0.0    0.0   \n",
       "\n",
       "   0.0.6  0.0.7  0.0.8  0.0.9  \n",
       "0    0.0    0.0    1.0    1.0  \n",
       "1    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "kfold_validation_score_store = []\n",
    "\n",
    "terget_name = [\"YES\",\"NO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = Sequential([\n",
    "    Dense(16,input_shape=(14,),activation=\"relu\"),\n",
    "    Dense(32,activation=\"relu\"),\n",
    "    Dense(32,activation=\"relu\"),\n",
    "    Dense(40,activation=\"relu\"),\n",
    "    Dense(54,activation=\"relu\"),\n",
    "    Dense(2,activation=\"softmax\")\n",
    "    ])\n",
    "'''\n",
    "model = Sequential([\n",
    "    Dense(8,input_shape=(14,),activation=\"relu\"),\n",
    "    Dense(7,activation=\"relu\"),\n",
    "    Dense(6,activation=\"relu\"),\n",
    "    Dense(2,activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "model.compile(\n",
    "    Adam(lr=.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #1\n",
      "Train on 750 samples, validate on 84 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.4699 - acc: 0.8347 - val_loss: 0.4623 - val_acc: 0.8452\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4700 - acc: 0.8320 - val_loss: 0.4605 - val_acc: 0.8333\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4698 - acc: 0.8253 - val_loss: 0.4619 - val_acc: 0.8214\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4678 - acc: 0.8333 - val_loss: 0.4582 - val_acc: 0.8333\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4676 - acc: 0.8347 - val_loss: 0.4572 - val_acc: 0.8333\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4662 - acc: 0.8320 - val_loss: 0.4576 - val_acc: 0.8452\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4661 - acc: 0.8360 - val_loss: 0.4559 - val_acc: 0.8333\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4659 - acc: 0.8373 - val_loss: 0.4546 - val_acc: 0.8452\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4648 - acc: 0.8347 - val_loss: 0.4536 - val_acc: 0.8333\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4641 - acc: 0.8373 - val_loss: 0.4548 - val_acc: 0.8214\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4615 - acc: 0.8347 - val_loss: 0.4546 - val_acc: 0.8214\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4633 - acc: 0.8307 - val_loss: 0.4522 - val_acc: 0.8333\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4619 - acc: 0.8333 - val_loss: 0.4507 - val_acc: 0.8452\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.4626 - acc: 0.8360 - val_loss: 0.4497 - val_acc: 0.8333\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.4604 - acc: 0.8360 - val_loss: 0.4489 - val_acc: 0.8333\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4596 - acc: 0.8347 - val_loss: 0.4491 - val_acc: 0.8333\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.4588 - acc: 0.8360 - val_loss: 0.4470 - val_acc: 0.8452\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4577 - acc: 0.8293 - val_loss: 0.4459 - val_acc: 0.8452\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4575 - acc: 0.8347 - val_loss: 0.4452 - val_acc: 0.8452\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4566 - acc: 0.8320 - val_loss: 0.4443 - val_acc: 0.8452\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4567 - acc: 0.8320 - val_loss: 0.4434 - val_acc: 0.8452\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4551 - acc: 0.8320 - val_loss: 0.4432 - val_acc: 0.8333\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4561 - acc: 0.8253 - val_loss: 0.4420 - val_acc: 0.8452\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4557 - acc: 0.8373 - val_loss: 0.4412 - val_acc: 0.8452\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4536 - acc: 0.8360 - val_loss: 0.4404 - val_acc: 0.8452\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4534 - acc: 0.8280 - val_loss: 0.4396 - val_acc: 0.8452\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4525 - acc: 0.8320 - val_loss: 0.4396 - val_acc: 0.8333\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.4519 - acc: 0.8320 - val_loss: 0.4381 - val_acc: 0.8452\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.4531 - acc: 0.8347 - val_loss: 0.4378 - val_acc: 0.8452\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.4502 - acc: 0.8360 - val_loss: 0.4372 - val_acc: 0.8333\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.4507 - acc: 0.8333 - val_loss: 0.4360 - val_acc: 0.8333\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.4501 - acc: 0.8293 - val_loss: 0.4353 - val_acc: 0.8333\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4525 - acc: 0.8360 - val_loss: 0.4353 - val_acc: 0.8452\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.4500 - acc: 0.8360 - val_loss: 0.4339 - val_acc: 0.8333\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.4500 - acc: 0.8320 - val_loss: 0.4333 - val_acc: 0.8452\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4482 - acc: 0.8360 - val_loss: 0.4344 - val_acc: 0.8333\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4479 - acc: 0.8307 - val_loss: 0.4318 - val_acc: 0.8333\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4517 - acc: 0.8253 - val_loss: 0.4326 - val_acc: 0.8333\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4479 - acc: 0.8373 - val_loss: 0.4334 - val_acc: 0.8333\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4469 - acc: 0.8280 - val_loss: 0.4300 - val_acc: 0.8333\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4451 - acc: 0.8427 - val_loss: 0.4384 - val_acc: 0.8095\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4462 - acc: 0.8347 - val_loss: 0.4294 - val_acc: 0.8452\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4462 - acc: 0.8240 - val_loss: 0.4281 - val_acc: 0.8333\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4455 - acc: 0.8320 - val_loss: 0.4284 - val_acc: 0.8333\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4449 - acc: 0.8320 - val_loss: 0.4268 - val_acc: 0.8333\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4447 - acc: 0.8360 - val_loss: 0.4266 - val_acc: 0.8333\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4433 - acc: 0.8387 - val_loss: 0.4267 - val_acc: 0.8333\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4440 - acc: 0.8347 - val_loss: 0.4252 - val_acc: 0.8333\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4431 - acc: 0.8333 - val_loss: 0.4244 - val_acc: 0.8333\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4434 - acc: 0.8293 - val_loss: 0.4255 - val_acc: 0.8333\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4416 - acc: 0.8320 - val_loss: 0.4237 - val_acc: 0.8333\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4407 - acc: 0.8347 - val_loss: 0.4230 - val_acc: 0.8333\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4424 - acc: 0.8307 - val_loss: 0.4234 - val_acc: 0.8333\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4409 - acc: 0.8347 - val_loss: 0.4267 - val_acc: 0.8452\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4429 - acc: 0.8253 - val_loss: 0.4210 - val_acc: 0.8333\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4414 - acc: 0.8387 - val_loss: 0.4206 - val_acc: 0.8333\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4431 - acc: 0.8373 - val_loss: 0.4199 - val_acc: 0.8333\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4404 - acc: 0.8267 - val_loss: 0.4195 - val_acc: 0.8333\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4387 - acc: 0.8320 - val_loss: 0.4190 - val_acc: 0.8333\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4388 - acc: 0.8320 - val_loss: 0.4185 - val_acc: 0.8333\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4386 - acc: 0.8347 - val_loss: 0.4184 - val_acc: 0.8333\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4393 - acc: 0.8307 - val_loss: 0.4217 - val_acc: 0.8452\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4401 - acc: 0.8293 - val_loss: 0.4168 - val_acc: 0.8333\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4379 - acc: 0.8293 - val_loss: 0.4163 - val_acc: 0.8333\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4419 - acc: 0.8240 - val_loss: 0.4162 - val_acc: 0.8333\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4376 - acc: 0.8320 - val_loss: 0.4154 - val_acc: 0.8333\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4359 - acc: 0.8347 - val_loss: 0.4166 - val_acc: 0.8333\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4357 - acc: 0.8293 - val_loss: 0.4158 - val_acc: 0.8333\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4402 - acc: 0.8373 - val_loss: 0.4151 - val_acc: 0.8333\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.4385 - acc: 0.8320 - val_loss: 0.4142 - val_acc: 0.8333\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4372 - acc: 0.8320 - val_loss: 0.4151 - val_acc: 0.8333\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4361 - acc: 0.8347 - val_loss: 0.4153 - val_acc: 0.8452\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.4351 - acc: 0.8307 - val_loss: 0.4150 - val_acc: 0.8452\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.4349 - acc: 0.8360 - val_loss: 0.4127 - val_acc: 0.8333\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4358 - acc: 0.8347 - val_loss: 0.4123 - val_acc: 0.8333\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4341 - acc: 0.8293 - val_loss: 0.4138 - val_acc: 0.8452\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4356 - acc: 0.8307 - val_loss: 0.4103 - val_acc: 0.8333\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4352 - acc: 0.8347 - val_loss: 0.4106 - val_acc: 0.8333\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4329 - acc: 0.8347 - val_loss: 0.4097 - val_acc: 0.8333\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4347 - acc: 0.8320 - val_loss: 0.4112 - val_acc: 0.8452\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4321 - acc: 0.8347 - val_loss: 0.4094 - val_acc: 0.8333\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4331 - acc: 0.8347 - val_loss: 0.4098 - val_acc: 0.8333\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4332 - acc: 0.8293 - val_loss: 0.4081 - val_acc: 0.8333\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4337 - acc: 0.8347 - val_loss: 0.4118 - val_acc: 0.8452\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4324 - acc: 0.8333 - val_loss: 0.4073 - val_acc: 0.8333\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.4327 - acc: 0.8307 - val_loss: 0.4093 - val_acc: 0.8452\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4318 - acc: 0.8280 - val_loss: 0.4065 - val_acc: 0.8333\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4319 - acc: 0.8347 - val_loss: 0.4064 - val_acc: 0.8333\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4331 - acc: 0.8320 - val_loss: 0.4079 - val_acc: 0.8452\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4323 - acc: 0.8347 - val_loss: 0.4069 - val_acc: 0.8452\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4328 - acc: 0.8320 - val_loss: 0.4082 - val_acc: 0.8452\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4308 - acc: 0.8360 - val_loss: 0.4074 - val_acc: 0.8452\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4346 - acc: 0.8227 - val_loss: 0.4043 - val_acc: 0.8333\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4320 - acc: 0.8307 - val_loss: 0.4055 - val_acc: 0.8333\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4303 - acc: 0.8307 - val_loss: 0.4046 - val_acc: 0.8452\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.4326 - acc: 0.8360 - val_loss: 0.4031 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 0s - loss: 0.4308 - acc: 0.8320 - val_loss: 0.4029 - val_acc: 0.8333\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4307 - acc: 0.8293 - val_loss: 0.4036 - val_acc: 0.8452\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.4302 - acc: 0.8293 - val_loss: 0.4094 - val_acc: 0.8452\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4321 - acc: 0.8280 - val_loss: 0.4019 - val_acc: 0.8333\n",
      "84/84 [==============================] - 0s 249us/step\n",
      "\n",
      "Fold score : [0.4018938555603936, 0.8333333361716497]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #2\n",
      "Train on 750 samples, validate on 84 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.4281 - acc: 0.8347 - val_loss: 0.4131 - val_acc: 0.8333\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4315 - acc: 0.8360 - val_loss: 0.4128 - val_acc: 0.8333\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4295 - acc: 0.8360 - val_loss: 0.4131 - val_acc: 0.8333\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4272 - acc: 0.8347 - val_loss: 0.4157 - val_acc: 0.8452\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4286 - acc: 0.8333 - val_loss: 0.4097 - val_acc: 0.8333\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4282 - acc: 0.8360 - val_loss: 0.4088 - val_acc: 0.8333\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4268 - acc: 0.8320 - val_loss: 0.4098 - val_acc: 0.8333\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4280 - acc: 0.8373 - val_loss: 0.4095 - val_acc: 0.8333\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4280 - acc: 0.8307 - val_loss: 0.4092 - val_acc: 0.8333\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4269 - acc: 0.8320 - val_loss: 0.4087 - val_acc: 0.8333\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4259 - acc: 0.8373 - val_loss: 0.4102 - val_acc: 0.8333\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4256 - acc: 0.8280 - val_loss: 0.4089 - val_acc: 0.8214\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4285 - acc: 0.8333 - val_loss: 0.4106 - val_acc: 0.8333\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4291 - acc: 0.8373 - val_loss: 0.4089 - val_acc: 0.8333\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4258 - acc: 0.8320 - val_loss: 0.4096 - val_acc: 0.8333\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4265 - acc: 0.8280 - val_loss: 0.4117 - val_acc: 0.8333\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4266 - acc: 0.8373 - val_loss: 0.4109 - val_acc: 0.8333\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.4260 - acc: 0.8347 - val_loss: 0.4089 - val_acc: 0.8214\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4252 - acc: 0.8333 - val_loss: 0.4093 - val_acc: 0.8333\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.4238 - acc: 0.8333 - val_loss: 0.4101 - val_acc: 0.8333\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.4261 - acc: 0.8373 - val_loss: 0.4090 - val_acc: 0.8214\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4238 - acc: 0.8333 - val_loss: 0.4114 - val_acc: 0.8333\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.4279 - acc: 0.8347 - val_loss: 0.4107 - val_acc: 0.8333\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.4262 - acc: 0.8387 - val_loss: 0.4092 - val_acc: 0.8333\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4227 - acc: 0.8347 - val_loss: 0.4102 - val_acc: 0.8333\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.4241 - acc: 0.8333 - val_loss: 0.4165 - val_acc: 0.8333\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4225 - acc: 0.8373 - val_loss: 0.4107 - val_acc: 0.8333\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4225 - acc: 0.8373 - val_loss: 0.4097 - val_acc: 0.8333\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4220 - acc: 0.8360 - val_loss: 0.4150 - val_acc: 0.8333\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4245 - acc: 0.8320 - val_loss: 0.4102 - val_acc: 0.8333\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.4218 - acc: 0.8347 - val_loss: 0.4113 - val_acc: 0.8333\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.4226 - acc: 0.8347 - val_loss: 0.4112 - val_acc: 0.8333\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4227 - acc: 0.8347 - val_loss: 0.4094 - val_acc: 0.8214\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4242 - acc: 0.8347 - val_loss: 0.4171 - val_acc: 0.8333\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4237 - acc: 0.8307 - val_loss: 0.4107 - val_acc: 0.8333\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4230 - acc: 0.8360 - val_loss: 0.4158 - val_acc: 0.8333\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4229 - acc: 0.8360 - val_loss: 0.4199 - val_acc: 0.8333\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4214 - acc: 0.8373 - val_loss: 0.4120 - val_acc: 0.8333\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4211 - acc: 0.8360 - val_loss: 0.4193 - val_acc: 0.8333\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4206 - acc: 0.8413 - val_loss: 0.4110 - val_acc: 0.8214\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4219 - acc: 0.8347 - val_loss: 0.4115 - val_acc: 0.8333\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4206 - acc: 0.8360 - val_loss: 0.4104 - val_acc: 0.8214\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4206 - acc: 0.8360 - val_loss: 0.4101 - val_acc: 0.8214\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4236 - acc: 0.8373 - val_loss: 0.4108 - val_acc: 0.8214\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4220 - acc: 0.8360 - val_loss: 0.4134 - val_acc: 0.8333\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4232 - acc: 0.8373 - val_loss: 0.4181 - val_acc: 0.8333\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4219 - acc: 0.8347 - val_loss: 0.4151 - val_acc: 0.8333\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.4212 - acc: 0.8373 - val_loss: 0.4118 - val_acc: 0.8214\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4200 - acc: 0.8373 - val_loss: 0.4108 - val_acc: 0.8214\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4192 - acc: 0.8347 - val_loss: 0.4175 - val_acc: 0.8333\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4207 - acc: 0.8360 - val_loss: 0.4104 - val_acc: 0.8214\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4195 - acc: 0.8387 - val_loss: 0.4127 - val_acc: 0.8333\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4199 - acc: 0.8387 - val_loss: 0.4109 - val_acc: 0.8214\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4187 - acc: 0.8387 - val_loss: 0.4154 - val_acc: 0.8333\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4181 - acc: 0.8360 - val_loss: 0.4106 - val_acc: 0.8214\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4203 - acc: 0.8373 - val_loss: 0.4179 - val_acc: 0.8333\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4200 - acc: 0.8360 - val_loss: 0.4175 - val_acc: 0.8333\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4206 - acc: 0.8360 - val_loss: 0.4161 - val_acc: 0.8333\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4206 - acc: 0.8373 - val_loss: 0.4149 - val_acc: 0.8333\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4190 - acc: 0.8373 - val_loss: 0.4135 - val_acc: 0.8214\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4186 - acc: 0.8387 - val_loss: 0.4141 - val_acc: 0.8214\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8387 - val_loss: 0.4123 - val_acc: 0.8214\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4203 - acc: 0.8373 - val_loss: 0.4122 - val_acc: 0.8214\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8347 - val_loss: 0.4116 - val_acc: 0.8214\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4182 - acc: 0.8373 - val_loss: 0.4112 - val_acc: 0.8214\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4186 - acc: 0.8373 - val_loss: 0.4116 - val_acc: 0.8214\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4178 - acc: 0.8387 - val_loss: 0.4152 - val_acc: 0.8214\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4185 - acc: 0.8373 - val_loss: 0.4155 - val_acc: 0.8333\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.4205 - acc: 0.8387 - val_loss: 0.4188 - val_acc: 0.8333\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4175 - acc: 0.8347 - val_loss: 0.4158 - val_acc: 0.8214\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4190 - acc: 0.8373 - val_loss: 0.4121 - val_acc: 0.8214\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4205 - acc: 0.8373 - val_loss: 0.4132 - val_acc: 0.8214\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4182 - acc: 0.8347 - val_loss: 0.4167 - val_acc: 0.8333\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4174 - acc: 0.8360 - val_loss: 0.4162 - val_acc: 0.8214\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4185 - acc: 0.8400 - val_loss: 0.4123 - val_acc: 0.8214\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.4160 - acc: 0.8373 - val_loss: 0.4121 - val_acc: 0.8214\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8373 - val_loss: 0.4139 - val_acc: 0.8214\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4197 - acc: 0.8360 - val_loss: 0.4124 - val_acc: 0.8214\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4163 - acc: 0.8387 - val_loss: 0.4155 - val_acc: 0.8214\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.4176 - acc: 0.8347 - val_loss: 0.4128 - val_acc: 0.8214\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4163 - acc: 0.8387 - val_loss: 0.4126 - val_acc: 0.8214\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4178 - acc: 0.8387 - val_loss: 0.4200 - val_acc: 0.8333\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4185 - acc: 0.8373 - val_loss: 0.4152 - val_acc: 0.8214\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4151 - acc: 0.8373 - val_loss: 0.4150 - val_acc: 0.8214\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4198 - acc: 0.8400 - val_loss: 0.4136 - val_acc: 0.8214\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4179 - acc: 0.8373 - val_loss: 0.4132 - val_acc: 0.8214\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4162 - acc: 0.8387 - val_loss: 0.4131 - val_acc: 0.8214\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4172 - acc: 0.8440 - val_loss: 0.4137 - val_acc: 0.8214\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.4171 - acc: 0.8387 - val_loss: 0.4156 - val_acc: 0.8214\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.4150 - acc: 0.8387 - val_loss: 0.4151 - val_acc: 0.8214\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4152 - acc: 0.8413 - val_loss: 0.4124 - val_acc: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      " - 1s - loss: 0.4165 - acc: 0.8373 - val_loss: 0.4132 - val_acc: 0.8214\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4150 - acc: 0.8413 - val_loss: 0.4126 - val_acc: 0.8214\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4148 - acc: 0.8413 - val_loss: 0.4121 - val_acc: 0.8214\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.4151 - acc: 0.8400 - val_loss: 0.4134 - val_acc: 0.8214\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4146 - acc: 0.8400 - val_loss: 0.4121 - val_acc: 0.8214\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.4171 - acc: 0.8373 - val_loss: 0.4125 - val_acc: 0.8214\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4161 - acc: 0.8373 - val_loss: 0.4162 - val_acc: 0.8214\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.4147 - acc: 0.8373 - val_loss: 0.4154 - val_acc: 0.8214\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.4144 - acc: 0.8400 - val_loss: 0.4124 - val_acc: 0.8214\n",
      "84/84 [==============================] - 0s 253us/step\n",
      "\n",
      "Fold score : [0.41238504364376977, 0.8214285742668879]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #3\n",
      "Train on 750 samples, validate on 84 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.4104 - acc: 0.8387 - val_loss: 0.4522 - val_acc: 0.8095\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4089 - acc: 0.8373 - val_loss: 0.4326 - val_acc: 0.8095\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4143 - acc: 0.8387 - val_loss: 0.4379 - val_acc: 0.8095\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4110 - acc: 0.8413 - val_loss: 0.4334 - val_acc: 0.8095\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4104 - acc: 0.8400 - val_loss: 0.4641 - val_acc: 0.8095\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4107 - acc: 0.8387 - val_loss: 0.4511 - val_acc: 0.8095\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4093 - acc: 0.8400 - val_loss: 0.4547 - val_acc: 0.8095\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4106 - acc: 0.8400 - val_loss: 0.4454 - val_acc: 0.8095\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4091 - acc: 0.8413 - val_loss: 0.4340 - val_acc: 0.8095\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4137 - acc: 0.8413 - val_loss: 0.4406 - val_acc: 0.8095\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4110 - acc: 0.8413 - val_loss: 0.4392 - val_acc: 0.8095\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4099 - acc: 0.8387 - val_loss: 0.4621 - val_acc: 0.8095\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8400 - val_loss: 0.4450 - val_acc: 0.8095\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8413 - val_loss: 0.4683 - val_acc: 0.8095\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4085 - acc: 0.8400 - val_loss: 0.4456 - val_acc: 0.8095\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4087 - acc: 0.8387 - val_loss: 0.4511 - val_acc: 0.8095\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4082 - acc: 0.8400 - val_loss: 0.4644 - val_acc: 0.8095\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.4093 - acc: 0.8400 - val_loss: 0.4563 - val_acc: 0.8095\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4099 - acc: 0.8387 - val_loss: 0.4670 - val_acc: 0.8095\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4090 - acc: 0.8387 - val_loss: 0.4483 - val_acc: 0.8095\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4090 - acc: 0.8400 - val_loss: 0.4556 - val_acc: 0.8095\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4126 - acc: 0.8413 - val_loss: 0.4445 - val_acc: 0.8095\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4096 - acc: 0.8387 - val_loss: 0.4423 - val_acc: 0.8095\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8387 - val_loss: 0.4515 - val_acc: 0.8095\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8413 - val_loss: 0.4597 - val_acc: 0.8095\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.4097 - acc: 0.8400 - val_loss: 0.4470 - val_acc: 0.8095\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8387 - val_loss: 0.4498 - val_acc: 0.8095\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8387 - val_loss: 0.4535 - val_acc: 0.8095\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4075 - acc: 0.8413 - val_loss: 0.4628 - val_acc: 0.8095\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4082 - acc: 0.8373 - val_loss: 0.4485 - val_acc: 0.8095\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4069 - acc: 0.8413 - val_loss: 0.4399 - val_acc: 0.8095\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4075 - acc: 0.8427 - val_loss: 0.4674 - val_acc: 0.8095\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4089 - acc: 0.8453 - val_loss: 0.4449 - val_acc: 0.8095\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4072 - acc: 0.8400 - val_loss: 0.4459 - val_acc: 0.8095\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8387 - val_loss: 0.4699 - val_acc: 0.8095\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8400 - val_loss: 0.4503 - val_acc: 0.8095\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8413 - val_loss: 0.4527 - val_acc: 0.8095\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4080 - acc: 0.8347 - val_loss: 0.4392 - val_acc: 0.8095\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.4072 - acc: 0.8373 - val_loss: 0.4579 - val_acc: 0.8095\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4079 - acc: 0.8400 - val_loss: 0.4475 - val_acc: 0.8095\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4069 - acc: 0.8400 - val_loss: 0.4564 - val_acc: 0.8095\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.4069 - acc: 0.8400 - val_loss: 0.4518 - val_acc: 0.8095\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.4069 - acc: 0.8400 - val_loss: 0.4669 - val_acc: 0.8095\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.4082 - acc: 0.8413 - val_loss: 0.4587 - val_acc: 0.8095\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.4060 - acc: 0.8413 - val_loss: 0.4642 - val_acc: 0.8095\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.4072 - acc: 0.8400 - val_loss: 0.4656 - val_acc: 0.8095\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4077 - acc: 0.8413 - val_loss: 0.4660 - val_acc: 0.8095\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8387 - val_loss: 0.4473 - val_acc: 0.8095\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8427 - val_loss: 0.4373 - val_acc: 0.8095\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4124 - acc: 0.8413 - val_loss: 0.4632 - val_acc: 0.8095\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4066 - acc: 0.8400 - val_loss: 0.4572 - val_acc: 0.8095\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4059 - acc: 0.8387 - val_loss: 0.4473 - val_acc: 0.8095\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8427 - val_loss: 0.4679 - val_acc: 0.8095\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8413 - val_loss: 0.4576 - val_acc: 0.8095\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4113 - acc: 0.8400 - val_loss: 0.4548 - val_acc: 0.8095\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4080 - acc: 0.8400 - val_loss: 0.4506 - val_acc: 0.8095\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4057 - acc: 0.8413 - val_loss: 0.4602 - val_acc: 0.8095\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4064 - acc: 0.8413 - val_loss: 0.4568 - val_acc: 0.8095\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8387 - val_loss: 0.4729 - val_acc: 0.8095\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4046 - acc: 0.8413 - val_loss: 0.4516 - val_acc: 0.8095\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4055 - acc: 0.8427 - val_loss: 0.4753 - val_acc: 0.8095\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4065 - acc: 0.8413 - val_loss: 0.4660 - val_acc: 0.8095\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4063 - acc: 0.8413 - val_loss: 0.4618 - val_acc: 0.8095\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4066 - acc: 0.8413 - val_loss: 0.4538 - val_acc: 0.8095\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8400 - val_loss: 0.4669 - val_acc: 0.8095\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4071 - acc: 0.8413 - val_loss: 0.4579 - val_acc: 0.8095\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4069 - acc: 0.8387 - val_loss: 0.4550 - val_acc: 0.8095\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4060 - acc: 0.8440 - val_loss: 0.4458 - val_acc: 0.8095\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4054 - acc: 0.8400 - val_loss: 0.4572 - val_acc: 0.8095\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4055 - acc: 0.8400 - val_loss: 0.4567 - val_acc: 0.8095\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4059 - acc: 0.8413 - val_loss: 0.4677 - val_acc: 0.8095\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4050 - acc: 0.8427 - val_loss: 0.4582 - val_acc: 0.8095\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8400 - val_loss: 0.4451 - val_acc: 0.8095\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4061 - acc: 0.8427 - val_loss: 0.4661 - val_acc: 0.8095\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4069 - acc: 0.8413 - val_loss: 0.4816 - val_acc: 0.8095\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4025 - acc: 0.8387 - val_loss: 0.4450 - val_acc: 0.8095\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4028 - acc: 0.8453 - val_loss: 0.5169 - val_acc: 0.8095\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4064 - acc: 0.8387 - val_loss: 0.4562 - val_acc: 0.8095\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8427 - val_loss: 0.4862 - val_acc: 0.8095\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8413 - val_loss: 0.4472 - val_acc: 0.8095\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4055 - acc: 0.8413 - val_loss: 0.4706 - val_acc: 0.8095\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8413 - val_loss: 0.4538 - val_acc: 0.8095\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8400 - val_loss: 0.4596 - val_acc: 0.8095\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8427 - val_loss: 0.4532 - val_acc: 0.8095\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8400 - val_loss: 0.4637 - val_acc: 0.8095\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8387 - val_loss: 0.4581 - val_acc: 0.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 0s - loss: 0.4038 - acc: 0.8413 - val_loss: 0.4724 - val_acc: 0.8095\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8400 - val_loss: 0.4756 - val_acc: 0.8095\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8440 - val_loss: 0.4804 - val_acc: 0.8095\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4052 - acc: 0.8427 - val_loss: 0.4591 - val_acc: 0.8095\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4043 - acc: 0.8387 - val_loss: 0.4529 - val_acc: 0.8095\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4043 - acc: 0.8440 - val_loss: 0.4946 - val_acc: 0.8214\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4042 - acc: 0.8427 - val_loss: 0.4605 - val_acc: 0.8095\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4066 - acc: 0.8427 - val_loss: 0.4635 - val_acc: 0.8095\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4053 - acc: 0.8413 - val_loss: 0.4811 - val_acc: 0.8095\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4032 - acc: 0.8387 - val_loss: 0.4559 - val_acc: 0.8095\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4066 - acc: 0.8400 - val_loss: 0.4752 - val_acc: 0.8095\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4051 - acc: 0.8427 - val_loss: 0.4918 - val_acc: 0.8095\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4059 - acc: 0.8400 - val_loss: 0.4703 - val_acc: 0.8095\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4044 - acc: 0.8413 - val_loss: 0.4892 - val_acc: 0.8095\n",
      "84/84 [==============================] - 0s 194us/step\n",
      "\n",
      "Fold score : [0.48917499042692636, 0.8095238095238095]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #4\n",
      "Train on 750 samples, validate on 84 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.4204 - acc: 0.8320 - val_loss: 0.3282 - val_acc: 0.8810\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4206 - acc: 0.8347 - val_loss: 0.3282 - val_acc: 0.8810\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4216 - acc: 0.8307 - val_loss: 0.3321 - val_acc: 0.8810\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4195 - acc: 0.8347 - val_loss: 0.3274 - val_acc: 0.8810\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4208 - acc: 0.8333 - val_loss: 0.3282 - val_acc: 0.8810\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4187 - acc: 0.8360 - val_loss: 0.3277 - val_acc: 0.8810\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4200 - acc: 0.8333 - val_loss: 0.3278 - val_acc: 0.8810\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4198 - acc: 0.8347 - val_loss: 0.3330 - val_acc: 0.8810\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4201 - acc: 0.8347 - val_loss: 0.3284 - val_acc: 0.8810\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8360 - val_loss: 0.3289 - val_acc: 0.8810\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4193 - acc: 0.8347 - val_loss: 0.3331 - val_acc: 0.8810\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4210 - acc: 0.8347 - val_loss: 0.3307 - val_acc: 0.8810\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8360 - val_loss: 0.3286 - val_acc: 0.8810\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4191 - acc: 0.8347 - val_loss: 0.3286 - val_acc: 0.8810\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8360 - val_loss: 0.3293 - val_acc: 0.8810\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8360 - val_loss: 0.3304 - val_acc: 0.8810\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4202 - acc: 0.8333 - val_loss: 0.3286 - val_acc: 0.8810\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8333 - val_loss: 0.3288 - val_acc: 0.8810\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8333 - val_loss: 0.3313 - val_acc: 0.8810\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8360 - val_loss: 0.3298 - val_acc: 0.8690\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8347 - val_loss: 0.3292 - val_acc: 0.8810\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4200 - acc: 0.8347 - val_loss: 0.3301 - val_acc: 0.8810\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4195 - acc: 0.8347 - val_loss: 0.3294 - val_acc: 0.8810\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4203 - acc: 0.8333 - val_loss: 0.3295 - val_acc: 0.8810\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4191 - acc: 0.8347 - val_loss: 0.3305 - val_acc: 0.8810\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4188 - acc: 0.8347 - val_loss: 0.3295 - val_acc: 0.8810\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4184 - acc: 0.8333 - val_loss: 0.3303 - val_acc: 0.8810\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4224 - acc: 0.8333 - val_loss: 0.3301 - val_acc: 0.8810\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4201 - acc: 0.8347 - val_loss: 0.3312 - val_acc: 0.8810\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4178 - acc: 0.8347 - val_loss: 0.3298 - val_acc: 0.8810\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8347 - val_loss: 0.3299 - val_acc: 0.8810\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4186 - acc: 0.8333 - val_loss: 0.3302 - val_acc: 0.8810\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4202 - acc: 0.8347 - val_loss: 0.3373 - val_acc: 0.8690\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4209 - acc: 0.8333 - val_loss: 0.3322 - val_acc: 0.8810\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4217 - acc: 0.8307 - val_loss: 0.3302 - val_acc: 0.8810\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4187 - acc: 0.8333 - val_loss: 0.3318 - val_acc: 0.8810\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4184 - acc: 0.8333 - val_loss: 0.3307 - val_acc: 0.8810\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8347 - val_loss: 0.3311 - val_acc: 0.8810\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4200 - acc: 0.8333 - val_loss: 0.3307 - val_acc: 0.8810\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4175 - acc: 0.8347 - val_loss: 0.3320 - val_acc: 0.8810\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4199 - acc: 0.8347 - val_loss: 0.3306 - val_acc: 0.8810\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4179 - acc: 0.8347 - val_loss: 0.3314 - val_acc: 0.8810\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4193 - acc: 0.8347 - val_loss: 0.3338 - val_acc: 0.8810\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4210 - acc: 0.8320 - val_loss: 0.3322 - val_acc: 0.8810\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4199 - acc: 0.8333 - val_loss: 0.3339 - val_acc: 0.8810\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8360 - val_loss: 0.3313 - val_acc: 0.8810\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4184 - acc: 0.8347 - val_loss: 0.3312 - val_acc: 0.8810\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4188 - acc: 0.8320 - val_loss: 0.3314 - val_acc: 0.8810\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4182 - acc: 0.8347 - val_loss: 0.3316 - val_acc: 0.8810\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4166 - acc: 0.8347 - val_loss: 0.3335 - val_acc: 0.8810\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8360 - val_loss: 0.3309 - val_acc: 0.8810\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4195 - acc: 0.8360 - val_loss: 0.3314 - val_acc: 0.8810\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8360 - val_loss: 0.3314 - val_acc: 0.8810\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4210 - acc: 0.8320 - val_loss: 0.3328 - val_acc: 0.8810\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8333 - val_loss: 0.3319 - val_acc: 0.8810\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8347 - val_loss: 0.3318 - val_acc: 0.8810\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4187 - acc: 0.8347 - val_loss: 0.3315 - val_acc: 0.8810\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4188 - acc: 0.8347 - val_loss: 0.3318 - val_acc: 0.8810\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4182 - acc: 0.8360 - val_loss: 0.3321 - val_acc: 0.8810\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8333 - val_loss: 0.3330 - val_acc: 0.8810\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4203 - acc: 0.8333 - val_loss: 0.3332 - val_acc: 0.8810\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4221 - acc: 0.8320 - val_loss: 0.3384 - val_acc: 0.8810\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4190 - acc: 0.8333 - val_loss: 0.3326 - val_acc: 0.8810\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4180 - acc: 0.8347 - val_loss: 0.3331 - val_acc: 0.8810\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4193 - acc: 0.8347 - val_loss: 0.3334 - val_acc: 0.8810\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4192 - acc: 0.8347 - val_loss: 0.3323 - val_acc: 0.8810\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4191 - acc: 0.8333 - val_loss: 0.3327 - val_acc: 0.8810\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4178 - acc: 0.8320 - val_loss: 0.3412 - val_acc: 0.8810\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4213 - acc: 0.8347 - val_loss: 0.3345 - val_acc: 0.8810\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8320 - val_loss: 0.3363 - val_acc: 0.8810\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4221 - acc: 0.8320 - val_loss: 0.3371 - val_acc: 0.8810\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4183 - acc: 0.8333 - val_loss: 0.3388 - val_acc: 0.8810\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4227 - acc: 0.8347 - val_loss: 0.3331 - val_acc: 0.8810\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4186 - acc: 0.8360 - val_loss: 0.3359 - val_acc: 0.8810\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4171 - acc: 0.8333 - val_loss: 0.3328 - val_acc: 0.8810\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4171 - acc: 0.8333 - val_loss: 0.3328 - val_acc: 0.8810\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4168 - acc: 0.8320 - val_loss: 0.3359 - val_acc: 0.8810\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4173 - acc: 0.8347 - val_loss: 0.3351 - val_acc: 0.8810\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4194 - acc: 0.8360 - val_loss: 0.3339 - val_acc: 0.8810\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4179 - acc: 0.8333 - val_loss: 0.3372 - val_acc: 0.8810\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4186 - acc: 0.8320 - val_loss: 0.3344 - val_acc: 0.8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      " - 0s - loss: 0.4179 - acc: 0.8333 - val_loss: 0.3330 - val_acc: 0.8810\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4205 - acc: 0.8320 - val_loss: 0.3361 - val_acc: 0.8810\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4197 - acc: 0.8347 - val_loss: 0.3338 - val_acc: 0.8810\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8333 - val_loss: 0.3340 - val_acc: 0.8690\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4179 - acc: 0.8333 - val_loss: 0.3338 - val_acc: 0.8810\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4184 - acc: 0.8333 - val_loss: 0.3332 - val_acc: 0.8810\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4184 - acc: 0.8347 - val_loss: 0.3336 - val_acc: 0.8810\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4177 - acc: 0.8333 - val_loss: 0.3334 - val_acc: 0.8810\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4172 - acc: 0.8347 - val_loss: 0.3347 - val_acc: 0.8810\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4201 - acc: 0.8320 - val_loss: 0.3341 - val_acc: 0.8810\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4193 - acc: 0.8333 - val_loss: 0.3340 - val_acc: 0.8810\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4161 - acc: 0.8320 - val_loss: 0.3350 - val_acc: 0.8810\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4177 - acc: 0.8347 - val_loss: 0.3372 - val_acc: 0.8810\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4212 - acc: 0.8333 - val_loss: 0.3342 - val_acc: 0.8810\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4192 - acc: 0.8347 - val_loss: 0.3337 - val_acc: 0.8810\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4182 - acc: 0.8347 - val_loss: 0.3336 - val_acc: 0.8810\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4175 - acc: 0.8333 - val_loss: 0.3337 - val_acc: 0.8810\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4174 - acc: 0.8333 - val_loss: 0.3359 - val_acc: 0.8810\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4181 - acc: 0.8333 - val_loss: 0.3382 - val_acc: 0.8810\n",
      "84/84 [==============================] - 0s 215us/step\n",
      "\n",
      "Fold score : [0.33817877372105914, 0.8809523752757481]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #5\n",
      "Train on 751 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.4091 - acc: 0.8362 - val_loss: 0.4216 - val_acc: 0.8313\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4094 - acc: 0.8402 - val_loss: 0.4176 - val_acc: 0.8313\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4109 - acc: 0.8349 - val_loss: 0.4062 - val_acc: 0.8434\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4069 - acc: 0.8375 - val_loss: 0.4217 - val_acc: 0.8313\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4097 - acc: 0.8402 - val_loss: 0.4072 - val_acc: 0.8313\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4099 - acc: 0.8402 - val_loss: 0.4118 - val_acc: 0.8313\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4087 - acc: 0.8402 - val_loss: 0.4133 - val_acc: 0.8313\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4091 - acc: 0.8402 - val_loss: 0.4094 - val_acc: 0.8313\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4082 - acc: 0.8402 - val_loss: 0.4091 - val_acc: 0.8313\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4089 - acc: 0.8402 - val_loss: 0.4134 - val_acc: 0.8313\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4111 - acc: 0.8389 - val_loss: 0.4079 - val_acc: 0.8313\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4106 - acc: 0.8402 - val_loss: 0.4102 - val_acc: 0.8313\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4089 - acc: 0.8389 - val_loss: 0.4114 - val_acc: 0.8313\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8375 - val_loss: 0.4147 - val_acc: 0.8313\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4094 - acc: 0.8375 - val_loss: 0.4081 - val_acc: 0.8313\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4089 - acc: 0.8389 - val_loss: 0.4097 - val_acc: 0.8313\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4097 - acc: 0.8389 - val_loss: 0.4096 - val_acc: 0.8313\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4082 - acc: 0.8402 - val_loss: 0.4105 - val_acc: 0.8313\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4107 - acc: 0.8402 - val_loss: 0.4138 - val_acc: 0.8313\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4090 - acc: 0.8402 - val_loss: 0.4243 - val_acc: 0.8313\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4150 - acc: 0.8375 - val_loss: 0.4111 - val_acc: 0.8313\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4131 - acc: 0.8415 - val_loss: 0.4114 - val_acc: 0.8313\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8389 - val_loss: 0.4171 - val_acc: 0.8313\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4090 - acc: 0.8389 - val_loss: 0.4087 - val_acc: 0.8434\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4060 - acc: 0.8375 - val_loss: 0.4310 - val_acc: 0.8313\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4129 - acc: 0.8362 - val_loss: 0.4133 - val_acc: 0.8313\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8415 - val_loss: 0.4111 - val_acc: 0.8313\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8389 - val_loss: 0.4100 - val_acc: 0.8313\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8402 - val_loss: 0.4093 - val_acc: 0.8313\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4134 - acc: 0.8415 - val_loss: 0.4101 - val_acc: 0.8313\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4096 - acc: 0.8415 - val_loss: 0.4138 - val_acc: 0.8313\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8389 - val_loss: 0.4185 - val_acc: 0.8313\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4105 - acc: 0.8389 - val_loss: 0.4147 - val_acc: 0.8313\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8389 - val_loss: 0.4261 - val_acc: 0.8313\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4076 - acc: 0.8362 - val_loss: 0.4094 - val_acc: 0.8434\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8389 - val_loss: 0.4119 - val_acc: 0.8313\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4089 - acc: 0.8402 - val_loss: 0.4120 - val_acc: 0.8313\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4092 - acc: 0.8375 - val_loss: 0.4117 - val_acc: 0.8313\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8389 - val_loss: 0.4114 - val_acc: 0.8313\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8402 - val_loss: 0.4107 - val_acc: 0.8313\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4121 - acc: 0.8389 - val_loss: 0.4151 - val_acc: 0.8313\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4085 - acc: 0.8362 - val_loss: 0.4102 - val_acc: 0.8434\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4092 - acc: 0.8389 - val_loss: 0.4112 - val_acc: 0.8313\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8389 - val_loss: 0.4146 - val_acc: 0.8313\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4066 - acc: 0.8362 - val_loss: 0.4311 - val_acc: 0.8313\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8375 - val_loss: 0.4107 - val_acc: 0.8434\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8402 - val_loss: 0.4116 - val_acc: 0.8313\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4085 - acc: 0.8362 - val_loss: 0.4156 - val_acc: 0.8313\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8362 - val_loss: 0.4110 - val_acc: 0.8434\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4100 - acc: 0.8402 - val_loss: 0.4159 - val_acc: 0.8313\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8389 - val_loss: 0.4161 - val_acc: 0.8313\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4072 - acc: 0.8402 - val_loss: 0.4163 - val_acc: 0.8313\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8402 - val_loss: 0.4149 - val_acc: 0.8313\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4088 - acc: 0.8402 - val_loss: 0.4246 - val_acc: 0.8313\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4088 - acc: 0.8375 - val_loss: 0.4248 - val_acc: 0.8313\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4113 - acc: 0.8402 - val_loss: 0.4129 - val_acc: 0.8313\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8389 - val_loss: 0.4175 - val_acc: 0.8313\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8402 - val_loss: 0.4118 - val_acc: 0.8313\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4092 - acc: 0.8402 - val_loss: 0.4132 - val_acc: 0.8313\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8402 - val_loss: 0.4178 - val_acc: 0.8313\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4070 - acc: 0.8389 - val_loss: 0.4139 - val_acc: 0.8313\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4085 - acc: 0.8389 - val_loss: 0.4121 - val_acc: 0.8434\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4082 - acc: 0.8429 - val_loss: 0.4204 - val_acc: 0.8313\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8402 - val_loss: 0.4202 - val_acc: 0.8313\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8389 - val_loss: 0.4176 - val_acc: 0.8313\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8375 - val_loss: 0.4139 - val_acc: 0.8313\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4087 - acc: 0.8389 - val_loss: 0.4173 - val_acc: 0.8313\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8402 - val_loss: 0.4143 - val_acc: 0.8313\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4076 - acc: 0.8389 - val_loss: 0.4123 - val_acc: 0.8434\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4099 - acc: 0.8415 - val_loss: 0.4149 - val_acc: 0.8313\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8375 - val_loss: 0.4210 - val_acc: 0.8313\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8402 - val_loss: 0.4164 - val_acc: 0.8313\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8402 - val_loss: 0.4144 - val_acc: 0.8313\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4074 - acc: 0.8415 - val_loss: 0.4145 - val_acc: 0.8313\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8402 - val_loss: 0.4143 - val_acc: 0.8313\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4060 - acc: 0.8389 - val_loss: 0.4301 - val_acc: 0.8313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      " - 0s - loss: 0.4070 - acc: 0.8375 - val_loss: 0.4134 - val_acc: 0.8434\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4097 - acc: 0.8375 - val_loss: 0.4146 - val_acc: 0.8313\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8402 - val_loss: 0.4223 - val_acc: 0.8313\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4093 - acc: 0.8375 - val_loss: 0.4163 - val_acc: 0.8313\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4066 - acc: 0.8375 - val_loss: 0.4145 - val_acc: 0.8313\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8389 - val_loss: 0.4248 - val_acc: 0.8313\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4105 - acc: 0.8402 - val_loss: 0.4204 - val_acc: 0.8313\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8402 - val_loss: 0.4146 - val_acc: 0.8313\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4074 - acc: 0.8402 - val_loss: 0.4169 - val_acc: 0.8313\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8375 - val_loss: 0.4233 - val_acc: 0.8313\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8415 - val_loss: 0.4181 - val_acc: 0.8313\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8402 - val_loss: 0.4167 - val_acc: 0.8313\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4090 - acc: 0.8349 - val_loss: 0.4232 - val_acc: 0.8313\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4067 - acc: 0.8362 - val_loss: 0.4175 - val_acc: 0.8313\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8402 - val_loss: 0.4147 - val_acc: 0.8313\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4074 - acc: 0.8402 - val_loss: 0.4174 - val_acc: 0.8313\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8362 - val_loss: 0.4145 - val_acc: 0.8313\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4072 - acc: 0.8375 - val_loss: 0.4177 - val_acc: 0.8313\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4065 - acc: 0.8389 - val_loss: 0.4168 - val_acc: 0.8313\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4090 - acc: 0.8402 - val_loss: 0.4141 - val_acc: 0.8313\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8402 - val_loss: 0.4180 - val_acc: 0.8313\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8389 - val_loss: 0.4152 - val_acc: 0.8313\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8389 - val_loss: 0.4386 - val_acc: 0.8313\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4067 - acc: 0.8389 - val_loss: 0.4158 - val_acc: 0.8313\n",
      "83/83 [==============================] - 0s 241us/step\n",
      "\n",
      "Fold score : [0.41578180890485467, 0.8313252990504345]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #6\n",
      "Train on 751 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.4153 - acc: 0.8362 - val_loss: 0.3626 - val_acc: 0.8675\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4134 - acc: 0.8349 - val_loss: 0.3625 - val_acc: 0.8675\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4121 - acc: 0.8362 - val_loss: 0.3638 - val_acc: 0.8675\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4129 - acc: 0.8349 - val_loss: 0.3736 - val_acc: 0.8675\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4122 - acc: 0.8362 - val_loss: 0.3770 - val_acc: 0.8554\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4149 - acc: 0.8322 - val_loss: 0.3667 - val_acc: 0.8675\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4164 - acc: 0.8362 - val_loss: 0.3739 - val_acc: 0.8675\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4117 - acc: 0.8349 - val_loss: 0.3739 - val_acc: 0.8675\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4136 - acc: 0.8375 - val_loss: 0.3650 - val_acc: 0.8675\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4135 - acc: 0.8362 - val_loss: 0.3699 - val_acc: 0.8675\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4119 - acc: 0.8349 - val_loss: 0.3599 - val_acc: 0.8675\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4125 - acc: 0.8349 - val_loss: 0.3606 - val_acc: 0.8675\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4155 - acc: 0.8362 - val_loss: 0.3624 - val_acc: 0.8675\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4116 - acc: 0.8349 - val_loss: 0.3684 - val_acc: 0.8675\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4127 - acc: 0.8349 - val_loss: 0.3713 - val_acc: 0.8675\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4127 - acc: 0.8349 - val_loss: 0.3680 - val_acc: 0.8675\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4134 - acc: 0.8336 - val_loss: 0.3722 - val_acc: 0.8675\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.4129 - acc: 0.8362 - val_loss: 0.3730 - val_acc: 0.8675\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4126 - acc: 0.8362 - val_loss: 0.3683 - val_acc: 0.8675\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4146 - acc: 0.8362 - val_loss: 0.3667 - val_acc: 0.8675\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4099 - acc: 0.8362 - val_loss: 0.3827 - val_acc: 0.8675\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4147 - acc: 0.8375 - val_loss: 0.3711 - val_acc: 0.8675\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4122 - acc: 0.8349 - val_loss: 0.3716 - val_acc: 0.8675\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.4129 - acc: 0.8336 - val_loss: 0.3697 - val_acc: 0.8675\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4147 - acc: 0.8349 - val_loss: 0.3708 - val_acc: 0.8675\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.4121 - acc: 0.8362 - val_loss: 0.3720 - val_acc: 0.8675\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4105 - acc: 0.8375 - val_loss: 0.3612 - val_acc: 0.8554\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4134 - acc: 0.8362 - val_loss: 0.3642 - val_acc: 0.8554\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4111 - acc: 0.8336 - val_loss: 0.3722 - val_acc: 0.8675\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4108 - acc: 0.8362 - val_loss: 0.3716 - val_acc: 0.8675\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4113 - acc: 0.8336 - val_loss: 0.3607 - val_acc: 0.8554\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4113 - acc: 0.8362 - val_loss: 0.3743 - val_acc: 0.8675\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4092 - acc: 0.8349 - val_loss: 0.3669 - val_acc: 0.8675\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4111 - acc: 0.8349 - val_loss: 0.3708 - val_acc: 0.8675\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4105 - acc: 0.8349 - val_loss: 0.3706 - val_acc: 0.8675\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.4103 - acc: 0.8336 - val_loss: 0.3728 - val_acc: 0.8675\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.4096 - acc: 0.8349 - val_loss: 0.3599 - val_acc: 0.8795\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.4117 - acc: 0.8375 - val_loss: 0.3832 - val_acc: 0.8675\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4092 - acc: 0.8349 - val_loss: 0.3672 - val_acc: 0.8554\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4085 - acc: 0.8349 - val_loss: 0.3835 - val_acc: 0.8675\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4114 - acc: 0.8362 - val_loss: 0.3747 - val_acc: 0.8675\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4121 - acc: 0.8362 - val_loss: 0.3712 - val_acc: 0.8675\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4115 - acc: 0.8362 - val_loss: 0.3739 - val_acc: 0.8675\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4092 - acc: 0.8362 - val_loss: 0.3671 - val_acc: 0.8675\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4089 - acc: 0.8375 - val_loss: 0.3660 - val_acc: 0.8554\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4076 - acc: 0.8349 - val_loss: 0.3833 - val_acc: 0.8675\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4081 - acc: 0.8349 - val_loss: 0.3630 - val_acc: 0.8554\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4104 - acc: 0.8349 - val_loss: 0.3740 - val_acc: 0.8675\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4094 - acc: 0.8349 - val_loss: 0.3783 - val_acc: 0.8675\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4092 - acc: 0.8336 - val_loss: 0.3917 - val_acc: 0.8554\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4121 - acc: 0.8362 - val_loss: 0.3726 - val_acc: 0.8675\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.4087 - acc: 0.8349 - val_loss: 0.3675 - val_acc: 0.8675\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4080 - acc: 0.8362 - val_loss: 0.3723 - val_acc: 0.8675\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4085 - acc: 0.8349 - val_loss: 0.3729 - val_acc: 0.8675\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4081 - acc: 0.8362 - val_loss: 0.3680 - val_acc: 0.8675\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8362 - val_loss: 0.3686 - val_acc: 0.8675\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8322 - val_loss: 0.3835 - val_acc: 0.8554\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4088 - acc: 0.8362 - val_loss: 0.3737 - val_acc: 0.8675\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8362 - val_loss: 0.3722 - val_acc: 0.8675\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8336 - val_loss: 0.3757 - val_acc: 0.8675\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8362 - val_loss: 0.3703 - val_acc: 0.8675\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8362 - val_loss: 0.3675 - val_acc: 0.8675\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4091 - acc: 0.8349 - val_loss: 0.3704 - val_acc: 0.8675\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4081 - acc: 0.8362 - val_loss: 0.3772 - val_acc: 0.8675\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8336 - val_loss: 0.3680 - val_acc: 0.8675\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4086 - acc: 0.8349 - val_loss: 0.3761 - val_acc: 0.8675\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8362 - val_loss: 0.3792 - val_acc: 0.8675\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4066 - acc: 0.8362 - val_loss: 0.3821 - val_acc: 0.8675\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4091 - acc: 0.8375 - val_loss: 0.3679 - val_acc: 0.8675\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4087 - acc: 0.8336 - val_loss: 0.3702 - val_acc: 0.8675\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8362 - val_loss: 0.3708 - val_acc: 0.8675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      " - 0s - loss: 0.4132 - acc: 0.8309 - val_loss: 0.3672 - val_acc: 0.8675\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8336 - val_loss: 0.3808 - val_acc: 0.8554\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4079 - acc: 0.8362 - val_loss: 0.3633 - val_acc: 0.8554\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8362 - val_loss: 0.3669 - val_acc: 0.8675\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4070 - acc: 0.8336 - val_loss: 0.3802 - val_acc: 0.8675\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8349 - val_loss: 0.3832 - val_acc: 0.8554\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4074 - acc: 0.8349 - val_loss: 0.3765 - val_acc: 0.8675\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4065 - acc: 0.8349 - val_loss: 0.3706 - val_acc: 0.8675\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4067 - acc: 0.8349 - val_loss: 0.3720 - val_acc: 0.8675\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4060 - acc: 0.8336 - val_loss: 0.3748 - val_acc: 0.8675\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4052 - acc: 0.8349 - val_loss: 0.3717 - val_acc: 0.8675\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8336 - val_loss: 0.3734 - val_acc: 0.8675\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4049 - acc: 0.8309 - val_loss: 0.3630 - val_acc: 0.8675\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8349 - val_loss: 0.3672 - val_acc: 0.8675\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8362 - val_loss: 0.3839 - val_acc: 0.8554\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.4054 - acc: 0.8349 - val_loss: 0.3711 - val_acc: 0.8675\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8375 - val_loss: 0.3633 - val_acc: 0.8675\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8349 - val_loss: 0.3673 - val_acc: 0.8675\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4078 - acc: 0.8362 - val_loss: 0.3794 - val_acc: 0.8675\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.4068 - acc: 0.8362 - val_loss: 0.3680 - val_acc: 0.8675\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4061 - acc: 0.8349 - val_loss: 0.3766 - val_acc: 0.8675\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8322 - val_loss: 0.3744 - val_acc: 0.8675\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4061 - acc: 0.8349 - val_loss: 0.3874 - val_acc: 0.8554\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4043 - acc: 0.8336 - val_loss: 0.3657 - val_acc: 0.8675\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4087 - acc: 0.8362 - val_loss: 0.3637 - val_acc: 0.8675\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4064 - acc: 0.8362 - val_loss: 0.3666 - val_acc: 0.8675\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4065 - acc: 0.8336 - val_loss: 0.3656 - val_acc: 0.8675\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8349 - val_loss: 0.3661 - val_acc: 0.8675\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4071 - acc: 0.8362 - val_loss: 0.3702 - val_acc: 0.8675\n",
      "83/83 [==============================] - 0s 251us/step\n",
      "\n",
      "Fold score : [0.37018557808485375, 0.8674698845449701]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #7\n",
      "Train on 751 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.4083 - acc: 0.8375 - val_loss: 0.3664 - val_acc: 0.8675\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.4115 - acc: 0.8389 - val_loss: 0.3659 - val_acc: 0.8675\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4061 - acc: 0.8349 - val_loss: 0.3732 - val_acc: 0.8554\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4048 - acc: 0.8349 - val_loss: 0.3668 - val_acc: 0.8675\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4053 - acc: 0.8362 - val_loss: 0.3718 - val_acc: 0.8675\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8336 - val_loss: 0.3844 - val_acc: 0.8554\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8375 - val_loss: 0.3625 - val_acc: 0.8675\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8362 - val_loss: 0.3634 - val_acc: 0.8675\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8375 - val_loss: 0.3684 - val_acc: 0.8675\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4057 - acc: 0.8349 - val_loss: 0.3659 - val_acc: 0.8675\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4077 - acc: 0.8362 - val_loss: 0.3744 - val_acc: 0.8554\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4084 - acc: 0.8336 - val_loss: 0.3689 - val_acc: 0.8675\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4070 - acc: 0.8362 - val_loss: 0.3689 - val_acc: 0.8675\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4057 - acc: 0.8349 - val_loss: 0.3615 - val_acc: 0.8675\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4070 - acc: 0.8362 - val_loss: 0.3633 - val_acc: 0.8675\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8362 - val_loss: 0.3731 - val_acc: 0.8554\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4053 - acc: 0.8336 - val_loss: 0.3625 - val_acc: 0.8675\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4026 - acc: 0.8362 - val_loss: 0.3786 - val_acc: 0.8554\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4070 - acc: 0.8322 - val_loss: 0.3670 - val_acc: 0.8675\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4043 - acc: 0.8336 - val_loss: 0.3631 - val_acc: 0.8675\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4068 - acc: 0.8349 - val_loss: 0.3653 - val_acc: 0.8675\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4042 - acc: 0.8349 - val_loss: 0.3628 - val_acc: 0.8675\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.4058 - acc: 0.8349 - val_loss: 0.3591 - val_acc: 0.8675\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4081 - acc: 0.8402 - val_loss: 0.3697 - val_acc: 0.8675\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4034 - acc: 0.8336 - val_loss: 0.3623 - val_acc: 0.8675\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4038 - acc: 0.8336 - val_loss: 0.3692 - val_acc: 0.8675\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4039 - acc: 0.8349 - val_loss: 0.3722 - val_acc: 0.8554\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4041 - acc: 0.8362 - val_loss: 0.3687 - val_acc: 0.8675\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4038 - acc: 0.8349 - val_loss: 0.3681 - val_acc: 0.8675\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8375 - val_loss: 0.3734 - val_acc: 0.8554\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.4045 - acc: 0.8362 - val_loss: 0.3667 - val_acc: 0.8675\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.4045 - acc: 0.8336 - val_loss: 0.3684 - val_acc: 0.8675\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4043 - acc: 0.8322 - val_loss: 0.3606 - val_acc: 0.8675\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.4027 - acc: 0.8362 - val_loss: 0.3633 - val_acc: 0.8675\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4039 - acc: 0.8349 - val_loss: 0.3659 - val_acc: 0.8675\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4037 - acc: 0.8349 - val_loss: 0.3612 - val_acc: 0.8675\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4052 - acc: 0.8389 - val_loss: 0.3684 - val_acc: 0.8675\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4041 - acc: 0.8336 - val_loss: 0.3627 - val_acc: 0.8675\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4049 - acc: 0.8349 - val_loss: 0.3784 - val_acc: 0.8554\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4041 - acc: 0.8349 - val_loss: 0.3642 - val_acc: 0.8675\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4041 - acc: 0.8362 - val_loss: 0.3626 - val_acc: 0.8675\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4025 - acc: 0.8362 - val_loss: 0.3632 - val_acc: 0.8675\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4028 - acc: 0.8349 - val_loss: 0.3642 - val_acc: 0.8675\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.4038 - acc: 0.8362 - val_loss: 0.3782 - val_acc: 0.8554\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.4051 - acc: 0.8336 - val_loss: 0.3690 - val_acc: 0.8675\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.4055 - acc: 0.8349 - val_loss: 0.3645 - val_acc: 0.8675\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4085 - acc: 0.8336 - val_loss: 0.3634 - val_acc: 0.8675\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.4030 - acc: 0.8322 - val_loss: 0.3564 - val_acc: 0.8554\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4048 - acc: 0.8349 - val_loss: 0.3582 - val_acc: 0.8675\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4020 - acc: 0.8389 - val_loss: 0.3797 - val_acc: 0.8554\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8349 - val_loss: 0.3604 - val_acc: 0.8675\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4025 - acc: 0.8362 - val_loss: 0.3628 - val_acc: 0.8675\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4047 - acc: 0.8349 - val_loss: 0.3602 - val_acc: 0.8675\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4019 - acc: 0.8336 - val_loss: 0.3620 - val_acc: 0.8675\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4024 - acc: 0.8362 - val_loss: 0.3663 - val_acc: 0.8675\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4024 - acc: 0.8362 - val_loss: 0.3829 - val_acc: 0.8554\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4039 - acc: 0.8362 - val_loss: 0.3672 - val_acc: 0.8675\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4035 - acc: 0.8336 - val_loss: 0.3659 - val_acc: 0.8675\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4014 - acc: 0.8362 - val_loss: 0.3598 - val_acc: 0.8675\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4026 - acc: 0.8375 - val_loss: 0.3617 - val_acc: 0.8675\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4017 - acc: 0.8362 - val_loss: 0.3631 - val_acc: 0.8675\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4023 - acc: 0.8336 - val_loss: 0.3750 - val_acc: 0.8554\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4021 - acc: 0.8349 - val_loss: 0.3595 - val_acc: 0.8675\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4015 - acc: 0.8322 - val_loss: 0.3595 - val_acc: 0.8675\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4016 - acc: 0.8362 - val_loss: 0.3622 - val_acc: 0.8675\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4020 - acc: 0.8322 - val_loss: 0.3664 - val_acc: 0.8675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      " - 0s - loss: 0.4010 - acc: 0.8349 - val_loss: 0.3584 - val_acc: 0.8675\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4029 - acc: 0.8389 - val_loss: 0.3628 - val_acc: 0.8675\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4026 - acc: 0.8336 - val_loss: 0.3573 - val_acc: 0.8554\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4038 - acc: 0.8402 - val_loss: 0.3720 - val_acc: 0.8554\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.4039 - acc: 0.8282 - val_loss: 0.3581 - val_acc: 0.8675\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4017 - acc: 0.8362 - val_loss: 0.3664 - val_acc: 0.8675\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4040 - acc: 0.8336 - val_loss: 0.3599 - val_acc: 0.8675\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4017 - acc: 0.8309 - val_loss: 0.3618 - val_acc: 0.8675\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4016 - acc: 0.8375 - val_loss: 0.3733 - val_acc: 0.8554\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3990 - acc: 0.8349 - val_loss: 0.3558 - val_acc: 0.8554\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4027 - acc: 0.8362 - val_loss: 0.3645 - val_acc: 0.8675\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4019 - acc: 0.8362 - val_loss: 0.3634 - val_acc: 0.8675\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4005 - acc: 0.8349 - val_loss: 0.3574 - val_acc: 0.8554\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4013 - acc: 0.8362 - val_loss: 0.3662 - val_acc: 0.8675\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4006 - acc: 0.8349 - val_loss: 0.3613 - val_acc: 0.8675\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4007 - acc: 0.8362 - val_loss: 0.3614 - val_acc: 0.8675\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.4010 - acc: 0.8336 - val_loss: 0.3650 - val_acc: 0.8675\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4020 - acc: 0.8362 - val_loss: 0.3683 - val_acc: 0.8675\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3988 - acc: 0.8362 - val_loss: 0.3552 - val_acc: 0.8554\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.4024 - acc: 0.8322 - val_loss: 0.3628 - val_acc: 0.8675\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3996 - acc: 0.8349 - val_loss: 0.3662 - val_acc: 0.8675\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4002 - acc: 0.8349 - val_loss: 0.3778 - val_acc: 0.8554\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4009 - acc: 0.8362 - val_loss: 0.3587 - val_acc: 0.8675\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.4043 - acc: 0.8349 - val_loss: 0.3631 - val_acc: 0.8675\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4000 - acc: 0.8336 - val_loss: 0.3580 - val_acc: 0.8554\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3999 - acc: 0.8349 - val_loss: 0.3605 - val_acc: 0.8675\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4000 - acc: 0.8322 - val_loss: 0.3691 - val_acc: 0.8675\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4021 - acc: 0.8349 - val_loss: 0.3606 - val_acc: 0.8675\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3995 - acc: 0.8362 - val_loss: 0.3559 - val_acc: 0.8554\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4057 - acc: 0.8402 - val_loss: 0.3622 - val_acc: 0.8675\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4013 - acc: 0.8362 - val_loss: 0.3606 - val_acc: 0.8675\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4004 - acc: 0.8336 - val_loss: 0.3603 - val_acc: 0.8675\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4017 - acc: 0.8402 - val_loss: 0.3606 - val_acc: 0.8675\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4009 - acc: 0.8362 - val_loss: 0.3572 - val_acc: 0.8554\n",
      "83/83 [==============================] - 0s 214us/step\n",
      "\n",
      "Fold score : [0.35721685943833315, 0.8554216831563467]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #8\n",
      "Train on 751 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.3706 - acc: 0.8549 - val_loss: 0.6523 - val_acc: 0.6988\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3695 - acc: 0.8509 - val_loss: 0.6676 - val_acc: 0.7108\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3680 - acc: 0.8509 - val_loss: 0.6504 - val_acc: 0.6988\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3676 - acc: 0.8535 - val_loss: 0.6559 - val_acc: 0.6988\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3686 - acc: 0.8615 - val_loss: 0.6396 - val_acc: 0.7108\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3699 - acc: 0.8575 - val_loss: 0.6277 - val_acc: 0.7108\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3691 - acc: 0.8535 - val_loss: 0.6454 - val_acc: 0.6988\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3680 - acc: 0.8535 - val_loss: 0.6411 - val_acc: 0.6988\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.3686 - acc: 0.8535 - val_loss: 0.6497 - val_acc: 0.6988\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3687 - acc: 0.8602 - val_loss: 0.6406 - val_acc: 0.7108\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.3703 - acc: 0.8589 - val_loss: 0.6443 - val_acc: 0.6988\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.3683 - acc: 0.8522 - val_loss: 0.6502 - val_acc: 0.6988\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.3680 - acc: 0.8575 - val_loss: 0.6294 - val_acc: 0.7108\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.3688 - acc: 0.8562 - val_loss: 0.6541 - val_acc: 0.6988\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.3678 - acc: 0.8535 - val_loss: 0.6517 - val_acc: 0.6988\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.3684 - acc: 0.8549 - val_loss: 0.6515 - val_acc: 0.6988\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3670 - acc: 0.8535 - val_loss: 0.6644 - val_acc: 0.6988\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.3673 - acc: 0.8535 - val_loss: 0.6645 - val_acc: 0.7108\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.3687 - acc: 0.8562 - val_loss: 0.6728 - val_acc: 0.7108\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3665 - acc: 0.8589 - val_loss: 0.6830 - val_acc: 0.6988\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.3669 - acc: 0.8575 - val_loss: 0.6268 - val_acc: 0.7108\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.3674 - acc: 0.8509 - val_loss: 0.6666 - val_acc: 0.6988\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.3672 - acc: 0.8535 - val_loss: 0.6570 - val_acc: 0.6988\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.3683 - acc: 0.8575 - val_loss: 0.6532 - val_acc: 0.6988\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.3687 - acc: 0.8522 - val_loss: 0.6665 - val_acc: 0.7108\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.3664 - acc: 0.8562 - val_loss: 0.6350 - val_acc: 0.6988\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.3673 - acc: 0.8535 - val_loss: 0.6437 - val_acc: 0.6988\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.3697 - acc: 0.8509 - val_loss: 0.6702 - val_acc: 0.7108\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.3672 - acc: 0.8522 - val_loss: 0.6433 - val_acc: 0.6988\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.3667 - acc: 0.8535 - val_loss: 0.6492 - val_acc: 0.6988\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3659 - acc: 0.8535 - val_loss: 0.6499 - val_acc: 0.6988\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3677 - acc: 0.8562 - val_loss: 0.6350 - val_acc: 0.7108\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.3677 - acc: 0.8562 - val_loss: 0.6322 - val_acc: 0.7108\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3675 - acc: 0.8509 - val_loss: 0.6501 - val_acc: 0.6988\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3688 - acc: 0.8509 - val_loss: 0.6631 - val_acc: 0.7108\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3672 - acc: 0.8509 - val_loss: 0.6570 - val_acc: 0.7108\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3676 - acc: 0.8589 - val_loss: 0.6675 - val_acc: 0.7108\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.3667 - acc: 0.8535 - val_loss: 0.6455 - val_acc: 0.6988\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3662 - acc: 0.8589 - val_loss: 0.6413 - val_acc: 0.6988\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3679 - acc: 0.8522 - val_loss: 0.6531 - val_acc: 0.7108\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3714 - acc: 0.8535 - val_loss: 0.6813 - val_acc: 0.6988\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3677 - acc: 0.8575 - val_loss: 0.6414 - val_acc: 0.7229\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3669 - acc: 0.8589 - val_loss: 0.6500 - val_acc: 0.6988\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3664 - acc: 0.8522 - val_loss: 0.6405 - val_acc: 0.7108\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3664 - acc: 0.8549 - val_loss: 0.6354 - val_acc: 0.7108\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3652 - acc: 0.8535 - val_loss: 0.6729 - val_acc: 0.6988\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3674 - acc: 0.8562 - val_loss: 0.6335 - val_acc: 0.7108\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3662 - acc: 0.8549 - val_loss: 0.6698 - val_acc: 0.6988\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3667 - acc: 0.8549 - val_loss: 0.6551 - val_acc: 0.7108\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3660 - acc: 0.8562 - val_loss: 0.6706 - val_acc: 0.7108\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3666 - acc: 0.8562 - val_loss: 0.6458 - val_acc: 0.6988\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.3683 - acc: 0.8535 - val_loss: 0.6699 - val_acc: 0.7108\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3653 - acc: 0.8535 - val_loss: 0.6734 - val_acc: 0.7108\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3654 - acc: 0.8535 - val_loss: 0.6323 - val_acc: 0.7108\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3672 - acc: 0.8535 - val_loss: 0.6384 - val_acc: 0.7108\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3670 - acc: 0.8522 - val_loss: 0.6783 - val_acc: 0.6988\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.3652 - acc: 0.8535 - val_loss: 0.6366 - val_acc: 0.7108\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3661 - acc: 0.8589 - val_loss: 0.6574 - val_acc: 0.7108\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3662 - acc: 0.8549 - val_loss: 0.6317 - val_acc: 0.7108\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3655 - acc: 0.8549 - val_loss: 0.6398 - val_acc: 0.7229\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3648 - acc: 0.8549 - val_loss: 0.6528 - val_acc: 0.7108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      " - 0s - loss: 0.3644 - acc: 0.8562 - val_loss: 0.6701 - val_acc: 0.6988\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3650 - acc: 0.8668 - val_loss: 0.6192 - val_acc: 0.7108\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3710 - acc: 0.8509 - val_loss: 0.6443 - val_acc: 0.6988\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3641 - acc: 0.8575 - val_loss: 0.6472 - val_acc: 0.6988\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3652 - acc: 0.8522 - val_loss: 0.6460 - val_acc: 0.6988\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3651 - acc: 0.8562 - val_loss: 0.6513 - val_acc: 0.7108\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3658 - acc: 0.8535 - val_loss: 0.6592 - val_acc: 0.6988\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.3649 - acc: 0.8589 - val_loss: 0.6480 - val_acc: 0.7108\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.3656 - acc: 0.8549 - val_loss: 0.6450 - val_acc: 0.7108\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3645 - acc: 0.8562 - val_loss: 0.6437 - val_acc: 0.7108\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3639 - acc: 0.8562 - val_loss: 0.6616 - val_acc: 0.7108\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3665 - acc: 0.8602 - val_loss: 0.6543 - val_acc: 0.7108\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3646 - acc: 0.8589 - val_loss: 0.6419 - val_acc: 0.7229\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.3650 - acc: 0.8589 - val_loss: 0.6469 - val_acc: 0.7108\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3642 - acc: 0.8535 - val_loss: 0.6490 - val_acc: 0.7108\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3651 - acc: 0.8615 - val_loss: 0.6796 - val_acc: 0.6988\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3647 - acc: 0.8562 - val_loss: 0.6427 - val_acc: 0.7229\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.3654 - acc: 0.8535 - val_loss: 0.6569 - val_acc: 0.6988\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.3641 - acc: 0.8589 - val_loss: 0.6553 - val_acc: 0.7108\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.3637 - acc: 0.8589 - val_loss: 0.6573 - val_acc: 0.6988\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.3640 - acc: 0.8562 - val_loss: 0.6653 - val_acc: 0.6988\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.3651 - acc: 0.8549 - val_loss: 0.6338 - val_acc: 0.7229\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3633 - acc: 0.8549 - val_loss: 0.6924 - val_acc: 0.7108\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3675 - acc: 0.8642 - val_loss: 0.6487 - val_acc: 0.7108\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3642 - acc: 0.8602 - val_loss: 0.6661 - val_acc: 0.6988\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3632 - acc: 0.8575 - val_loss: 0.6377 - val_acc: 0.7229\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3649 - acc: 0.8562 - val_loss: 0.6598 - val_acc: 0.6988\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3631 - acc: 0.8562 - val_loss: 0.6577 - val_acc: 0.7108\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3633 - acc: 0.8628 - val_loss: 0.6315 - val_acc: 0.7229\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3669 - acc: 0.8575 - val_loss: 0.6907 - val_acc: 0.7108\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3646 - acc: 0.8602 - val_loss: 0.6418 - val_acc: 0.7229\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3640 - acc: 0.8549 - val_loss: 0.6578 - val_acc: 0.7108\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.3632 - acc: 0.8562 - val_loss: 0.6232 - val_acc: 0.7229\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.3639 - acc: 0.8562 - val_loss: 0.6353 - val_acc: 0.7229\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3626 - acc: 0.8602 - val_loss: 0.6724 - val_acc: 0.6988\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3641 - acc: 0.8615 - val_loss: 0.6460 - val_acc: 0.7229\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3631 - acc: 0.8575 - val_loss: 0.6418 - val_acc: 0.7229\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3638 - acc: 0.8589 - val_loss: 0.6463 - val_acc: 0.7229\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.3633 - acc: 0.8589 - val_loss: 0.6664 - val_acc: 0.7108\n",
      "83/83 [==============================] - 0s 202us/step\n",
      "\n",
      "Fold score : [0.6664446786225561, 0.7108433763664889]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #9\n",
      "Train on 751 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.3836 - acc: 0.8442 - val_loss: 0.4573 - val_acc: 0.8313\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3834 - acc: 0.8455 - val_loss: 0.4689 - val_acc: 0.8313\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3828 - acc: 0.8469 - val_loss: 0.4538 - val_acc: 0.8313\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3830 - acc: 0.8429 - val_loss: 0.4566 - val_acc: 0.8313\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3821 - acc: 0.8482 - val_loss: 0.4588 - val_acc: 0.8313\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3839 - acc: 0.8429 - val_loss: 0.4692 - val_acc: 0.8313\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.3836 - acc: 0.8482 - val_loss: 0.4504 - val_acc: 0.8313\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.3837 - acc: 0.8415 - val_loss: 0.4513 - val_acc: 0.8313\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.3816 - acc: 0.8429 - val_loss: 0.4811 - val_acc: 0.7952\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.3835 - acc: 0.8429 - val_loss: 0.4561 - val_acc: 0.8313\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.3825 - acc: 0.8429 - val_loss: 0.4547 - val_acc: 0.8313\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.3826 - acc: 0.8455 - val_loss: 0.4552 - val_acc: 0.8313\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.3823 - acc: 0.8442 - val_loss: 0.4569 - val_acc: 0.8313\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.3818 - acc: 0.8482 - val_loss: 0.4523 - val_acc: 0.8313\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.3833 - acc: 0.8415 - val_loss: 0.4598 - val_acc: 0.8313\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.3841 - acc: 0.8469 - val_loss: 0.4656 - val_acc: 0.8313\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3814 - acc: 0.8482 - val_loss: 0.4582 - val_acc: 0.8313\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.3829 - acc: 0.8442 - val_loss: 0.4464 - val_acc: 0.8313\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.3825 - acc: 0.8442 - val_loss: 0.4538 - val_acc: 0.8313\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3836 - acc: 0.8455 - val_loss: 0.4537 - val_acc: 0.8313\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3820 - acc: 0.8455 - val_loss: 0.4593 - val_acc: 0.8313\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.3812 - acc: 0.8522 - val_loss: 0.4481 - val_acc: 0.8313\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.3846 - acc: 0.8442 - val_loss: 0.4424 - val_acc: 0.8313\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.3827 - acc: 0.8442 - val_loss: 0.4710 - val_acc: 0.8072\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.3816 - acc: 0.8469 - val_loss: 0.4579 - val_acc: 0.8313\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.3850 - acc: 0.8482 - val_loss: 0.4708 - val_acc: 0.8193\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3822 - acc: 0.8455 - val_loss: 0.4768 - val_acc: 0.8072\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.3823 - acc: 0.8495 - val_loss: 0.4520 - val_acc: 0.8313\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.3811 - acc: 0.8429 - val_loss: 0.4551 - val_acc: 0.8313\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3804 - acc: 0.8455 - val_loss: 0.4469 - val_acc: 0.8313\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3812 - acc: 0.8402 - val_loss: 0.4681 - val_acc: 0.8193\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3807 - acc: 0.8469 - val_loss: 0.4561 - val_acc: 0.8313\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3807 - acc: 0.8455 - val_loss: 0.4523 - val_acc: 0.8313\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3827 - acc: 0.8442 - val_loss: 0.4709 - val_acc: 0.8072\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3809 - acc: 0.8482 - val_loss: 0.4639 - val_acc: 0.8193\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3808 - acc: 0.8482 - val_loss: 0.4551 - val_acc: 0.8313\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3808 - acc: 0.8442 - val_loss: 0.4491 - val_acc: 0.8313\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3828 - acc: 0.8375 - val_loss: 0.4574 - val_acc: 0.8313\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3806 - acc: 0.8522 - val_loss: 0.4688 - val_acc: 0.8193\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3804 - acc: 0.8402 - val_loss: 0.4639 - val_acc: 0.8313\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3817 - acc: 0.8469 - val_loss: 0.4671 - val_acc: 0.8193\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3823 - acc: 0.8522 - val_loss: 0.4605 - val_acc: 0.8313\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3804 - acc: 0.8509 - val_loss: 0.4535 - val_acc: 0.8313\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3797 - acc: 0.8442 - val_loss: 0.4477 - val_acc: 0.8313\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3787 - acc: 0.8469 - val_loss: 0.4803 - val_acc: 0.8072\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3805 - acc: 0.8469 - val_loss: 0.4684 - val_acc: 0.8072\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3807 - acc: 0.8415 - val_loss: 0.4477 - val_acc: 0.8313\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3811 - acc: 0.8442 - val_loss: 0.4695 - val_acc: 0.8193\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3807 - acc: 0.8469 - val_loss: 0.4705 - val_acc: 0.8072\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3809 - acc: 0.8442 - val_loss: 0.4537 - val_acc: 0.8313\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3807 - acc: 0.8429 - val_loss: 0.4988 - val_acc: 0.7952\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3831 - acc: 0.8482 - val_loss: 0.4784 - val_acc: 0.8072\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3789 - acc: 0.8509 - val_loss: 0.4466 - val_acc: 0.8313\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3777 - acc: 0.8442 - val_loss: 0.4874 - val_acc: 0.8072\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3835 - acc: 0.8402 - val_loss: 0.4540 - val_acc: 0.8313\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3791 - acc: 0.8495 - val_loss: 0.4542 - val_acc: 0.8313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      " - 0s - loss: 0.3776 - acc: 0.8482 - val_loss: 0.4802 - val_acc: 0.8072\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3826 - acc: 0.8442 - val_loss: 0.4622 - val_acc: 0.8193\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3788 - acc: 0.8442 - val_loss: 0.4595 - val_acc: 0.8313\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3794 - acc: 0.8482 - val_loss: 0.4595 - val_acc: 0.8193\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3788 - acc: 0.8482 - val_loss: 0.4668 - val_acc: 0.8072\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3786 - acc: 0.8442 - val_loss: 0.4692 - val_acc: 0.8072\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3784 - acc: 0.8509 - val_loss: 0.4582 - val_acc: 0.8313\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3803 - acc: 0.8455 - val_loss: 0.4679 - val_acc: 0.8072\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3789 - acc: 0.8482 - val_loss: 0.4593 - val_acc: 0.8313\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3773 - acc: 0.8469 - val_loss: 0.4504 - val_acc: 0.8313\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3788 - acc: 0.8482 - val_loss: 0.4553 - val_acc: 0.8313\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3806 - acc: 0.8469 - val_loss: 0.4576 - val_acc: 0.8313\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3785 - acc: 0.8402 - val_loss: 0.4766 - val_acc: 0.8072\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3807 - acc: 0.8469 - val_loss: 0.4723 - val_acc: 0.8072\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3781 - acc: 0.8455 - val_loss: 0.4582 - val_acc: 0.8313\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3779 - acc: 0.8429 - val_loss: 0.4593 - val_acc: 0.8313\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3793 - acc: 0.8482 - val_loss: 0.4698 - val_acc: 0.8072\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3799 - acc: 0.8455 - val_loss: 0.4633 - val_acc: 0.8193\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.3798 - acc: 0.8442 - val_loss: 0.4496 - val_acc: 0.8313\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3775 - acc: 0.8495 - val_loss: 0.4600 - val_acc: 0.8313\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3782 - acc: 0.8429 - val_loss: 0.4514 - val_acc: 0.8313\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3801 - acc: 0.8415 - val_loss: 0.4548 - val_acc: 0.8313\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.3789 - acc: 0.8429 - val_loss: 0.4696 - val_acc: 0.8072\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3773 - acc: 0.8495 - val_loss: 0.4600 - val_acc: 0.8193\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.3771 - acc: 0.8469 - val_loss: 0.4568 - val_acc: 0.8313\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3807 - acc: 0.8482 - val_loss: 0.4501 - val_acc: 0.8313\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.3772 - acc: 0.8402 - val_loss: 0.4672 - val_acc: 0.8072\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3783 - acc: 0.8469 - val_loss: 0.4720 - val_acc: 0.8072\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3785 - acc: 0.8415 - val_loss: 0.4671 - val_acc: 0.8072\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3787 - acc: 0.8482 - val_loss: 0.4797 - val_acc: 0.8072\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3789 - acc: 0.8455 - val_loss: 0.4663 - val_acc: 0.8072\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3760 - acc: 0.8469 - val_loss: 0.4582 - val_acc: 0.8313\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3785 - acc: 0.8509 - val_loss: 0.4505 - val_acc: 0.8313\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3782 - acc: 0.8442 - val_loss: 0.4667 - val_acc: 0.8072\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3770 - acc: 0.8495 - val_loss: 0.4627 - val_acc: 0.8193\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3773 - acc: 0.8455 - val_loss: 0.4732 - val_acc: 0.8072\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3776 - acc: 0.8495 - val_loss: 0.4541 - val_acc: 0.8313\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3778 - acc: 0.8415 - val_loss: 0.4663 - val_acc: 0.8072\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.3791 - acc: 0.8442 - val_loss: 0.4757 - val_acc: 0.8072\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3763 - acc: 0.8495 - val_loss: 0.4499 - val_acc: 0.8313\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3814 - acc: 0.8469 - val_loss: 0.4701 - val_acc: 0.8072\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3803 - acc: 0.8455 - val_loss: 0.4690 - val_acc: 0.8072\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3763 - acc: 0.8469 - val_loss: 0.4652 - val_acc: 0.8072\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.3763 - acc: 0.8482 - val_loss: 0.4725 - val_acc: 0.8072\n",
      "83/83 [==============================] - 0s 190us/step\n",
      "\n",
      "Fold score : [0.4725043188376599, 0.8072289170989071]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n",
      "fold #10\n",
      "Train on 751 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.4007 - acc: 0.8349 - val_loss: 0.2620 - val_acc: 0.9277\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4011 - acc: 0.8336 - val_loss: 0.2601 - val_acc: 0.9277\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3999 - acc: 0.8336 - val_loss: 0.2708 - val_acc: 0.9157\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3991 - acc: 0.8336 - val_loss: 0.2569 - val_acc: 0.9157\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3979 - acc: 0.8349 - val_loss: 0.2665 - val_acc: 0.9157\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3998 - acc: 0.8322 - val_loss: 0.2725 - val_acc: 0.9157\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3992 - acc: 0.8322 - val_loss: 0.2734 - val_acc: 0.9157\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4007 - acc: 0.8309 - val_loss: 0.2570 - val_acc: 0.9157\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4005 - acc: 0.8442 - val_loss: 0.2685 - val_acc: 0.9157\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3995 - acc: 0.8336 - val_loss: 0.2570 - val_acc: 0.9157\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3998 - acc: 0.8336 - val_loss: 0.2608 - val_acc: 0.9277\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3975 - acc: 0.8282 - val_loss: 0.2590 - val_acc: 0.9277\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4002 - acc: 0.8336 - val_loss: 0.2637 - val_acc: 0.9157\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.3980 - acc: 0.8375 - val_loss: 0.2603 - val_acc: 0.9277\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3980 - acc: 0.8336 - val_loss: 0.2611 - val_acc: 0.9277\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3985 - acc: 0.8309 - val_loss: 0.2638 - val_acc: 0.9277\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3989 - acc: 0.8282 - val_loss: 0.2603 - val_acc: 0.9277\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3974 - acc: 0.8362 - val_loss: 0.2706 - val_acc: 0.9157\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3981 - acc: 0.8349 - val_loss: 0.2595 - val_acc: 0.9277\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4004 - acc: 0.8349 - val_loss: 0.2617 - val_acc: 0.9277\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3981 - acc: 0.8349 - val_loss: 0.2550 - val_acc: 0.9157\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.4002 - acc: 0.8309 - val_loss: 0.2588 - val_acc: 0.9277\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3987 - acc: 0.8282 - val_loss: 0.2573 - val_acc: 0.9157\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.3984 - acc: 0.8336 - val_loss: 0.2612 - val_acc: 0.9277\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.3979 - acc: 0.8349 - val_loss: 0.2677 - val_acc: 0.9157\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3975 - acc: 0.8309 - val_loss: 0.2602 - val_acc: 0.9277\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.3982 - acc: 0.8322 - val_loss: 0.2680 - val_acc: 0.9157\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3975 - acc: 0.8336 - val_loss: 0.2674 - val_acc: 0.9277\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.4002 - acc: 0.8336 - val_loss: 0.2703 - val_acc: 0.9277\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.3997 - acc: 0.8309 - val_loss: 0.2654 - val_acc: 0.9277\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3982 - acc: 0.8349 - val_loss: 0.2659 - val_acc: 0.9277\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3988 - acc: 0.8322 - val_loss: 0.2650 - val_acc: 0.9157\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3995 - acc: 0.8336 - val_loss: 0.2574 - val_acc: 0.9157\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3978 - acc: 0.8375 - val_loss: 0.2667 - val_acc: 0.9157\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.4029 - acc: 0.8256 - val_loss: 0.2656 - val_acc: 0.9277\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3988 - acc: 0.8296 - val_loss: 0.2590 - val_acc: 0.9157\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3991 - acc: 0.8362 - val_loss: 0.2558 - val_acc: 0.9157\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4016 - acc: 0.8362 - val_loss: 0.2622 - val_acc: 0.9277\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3979 - acc: 0.8336 - val_loss: 0.2602 - val_acc: 0.9277\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3979 - acc: 0.8322 - val_loss: 0.2760 - val_acc: 0.9157\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3970 - acc: 0.8336 - val_loss: 0.2628 - val_acc: 0.9277\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3976 - acc: 0.8336 - val_loss: 0.2630 - val_acc: 0.9277\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3978 - acc: 0.8322 - val_loss: 0.2762 - val_acc: 0.9157\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3990 - acc: 0.8296 - val_loss: 0.2549 - val_acc: 0.9157\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3981 - acc: 0.8362 - val_loss: 0.2598 - val_acc: 0.9157\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3972 - acc: 0.8375 - val_loss: 0.2624 - val_acc: 0.9277\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3982 - acc: 0.8242 - val_loss: 0.2605 - val_acc: 0.9277\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3972 - acc: 0.8322 - val_loss: 0.2584 - val_acc: 0.9157\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4003 - acc: 0.8282 - val_loss: 0.2594 - val_acc: 0.9277\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3978 - acc: 0.8336 - val_loss: 0.2639 - val_acc: 0.9277\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3965 - acc: 0.8349 - val_loss: 0.2621 - val_acc: 0.9277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      " - 0s - loss: 0.3979 - acc: 0.8296 - val_loss: 0.2633 - val_acc: 0.9277\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3987 - acc: 0.8375 - val_loss: 0.2573 - val_acc: 0.9157\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3968 - acc: 0.8349 - val_loss: 0.2630 - val_acc: 0.9277\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3974 - acc: 0.8269 - val_loss: 0.2578 - val_acc: 0.9157\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3984 - acc: 0.8322 - val_loss: 0.2554 - val_acc: 0.9157\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4009 - acc: 0.8349 - val_loss: 0.2616 - val_acc: 0.9277\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3990 - acc: 0.8322 - val_loss: 0.2668 - val_acc: 0.9157\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3964 - acc: 0.8309 - val_loss: 0.2618 - val_acc: 0.9277\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3987 - acc: 0.8309 - val_loss: 0.2742 - val_acc: 0.9157\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3965 - acc: 0.8336 - val_loss: 0.2656 - val_acc: 0.9157\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3973 - acc: 0.8336 - val_loss: 0.2644 - val_acc: 0.9277\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3993 - acc: 0.8336 - val_loss: 0.2636 - val_acc: 0.9277\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3974 - acc: 0.8362 - val_loss: 0.2618 - val_acc: 0.9277\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3988 - acc: 0.8309 - val_loss: 0.2639 - val_acc: 0.9277\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3985 - acc: 0.8296 - val_loss: 0.2574 - val_acc: 0.9157\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3983 - acc: 0.8415 - val_loss: 0.2671 - val_acc: 0.9157\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3960 - acc: 0.8349 - val_loss: 0.2597 - val_acc: 0.9157\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.3968 - acc: 0.8362 - val_loss: 0.2657 - val_acc: 0.9277\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.3982 - acc: 0.8336 - val_loss: 0.2589 - val_acc: 0.9157\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3950 - acc: 0.8362 - val_loss: 0.2724 - val_acc: 0.9157\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3959 - acc: 0.8322 - val_loss: 0.2589 - val_acc: 0.9157\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3974 - acc: 0.8322 - val_loss: 0.2613 - val_acc: 0.9277\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3967 - acc: 0.8336 - val_loss: 0.2603 - val_acc: 0.9277\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.3983 - acc: 0.8336 - val_loss: 0.2642 - val_acc: 0.9277\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3952 - acc: 0.8402 - val_loss: 0.2683 - val_acc: 0.9157\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3968 - acc: 0.8336 - val_loss: 0.2663 - val_acc: 0.9277\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3972 - acc: 0.8336 - val_loss: 0.2584 - val_acc: 0.9157\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.3969 - acc: 0.8322 - val_loss: 0.2606 - val_acc: 0.9157\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.3961 - acc: 0.8322 - val_loss: 0.2629 - val_acc: 0.9277\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.3960 - acc: 0.8336 - val_loss: 0.2623 - val_acc: 0.9277\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.3954 - acc: 0.8362 - val_loss: 0.2745 - val_acc: 0.9157\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.3985 - acc: 0.8296 - val_loss: 0.2683 - val_acc: 0.9157\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3952 - acc: 0.8349 - val_loss: 0.2604 - val_acc: 0.9157\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3968 - acc: 0.8296 - val_loss: 0.2709 - val_acc: 0.9157\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3955 - acc: 0.8322 - val_loss: 0.2602 - val_acc: 0.9157\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3962 - acc: 0.8349 - val_loss: 0.2620 - val_acc: 0.9277\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3955 - acc: 0.8375 - val_loss: 0.2580 - val_acc: 0.9157\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3949 - acc: 0.8362 - val_loss: 0.2632 - val_acc: 0.9277\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3993 - acc: 0.8336 - val_loss: 0.2678 - val_acc: 0.9157\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3994 - acc: 0.8282 - val_loss: 0.2667 - val_acc: 0.9157\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3954 - acc: 0.8402 - val_loss: 0.2654 - val_acc: 0.9277\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3959 - acc: 0.8362 - val_loss: 0.2552 - val_acc: 0.9157\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.3978 - acc: 0.8336 - val_loss: 0.2671 - val_acc: 0.9157\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.3956 - acc: 0.8309 - val_loss: 0.2559 - val_acc: 0.9157\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3974 - acc: 0.8375 - val_loss: 0.2624 - val_acc: 0.9277\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3964 - acc: 0.8349 - val_loss: 0.2633 - val_acc: 0.9157\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3955 - acc: 0.8322 - val_loss: 0.2649 - val_acc: 0.9157\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3978 - acc: 0.8296 - val_loss: 0.2639 - val_acc: 0.9277\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.3967 - acc: 0.8269 - val_loss: 0.2604 - val_acc: 0.9157\n",
      "83/83 [==============================] - 0s 233us/step\n",
      "\n",
      "Fold score : [0.2603911940591881, 0.9156626556293074]\n",
      "\n",
      "\n",
      "new\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for train,test in kf.split(X):\n",
    "    fold += 1\n",
    "    print(\"fold #{}\".format(fold))\n",
    "    x_train = X[train]\n",
    "    y_train = Y[train]\n",
    "    x_test = X[test]\n",
    "    y_test = Y[test]\n",
    "    \n",
    "    model = Sequential([\n",
    "    Dense(8,input_shape=(14,),activation=\"relu\"),\n",
    "    Dense(7,activation=\"relu\"),\n",
    "    Dense(6,activation=\"relu\"),\n",
    "    Dense(2,activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        Adam(lr=.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.fit(x_train, y_train,validation_data = (x_test,y_test),batch_size=10,epochs=100,shuffle=True,verbose=2)\n",
    "    \n",
    "    model.save(\"heart_attack_risk_prediction_fold_no_\"+str(fold)+\"_with_cross_validation.h5\")\n",
    "    \n",
    "    #rounded_predections = model.predict_classes(X_test,batch_size=10,verbose=0)\n",
    "    pred2 = model.predict(x_test)\n",
    "    pred = model.predict_classes(x_test)\n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    kfold_validation_score_store.append(score)\n",
    "    #oos_y.append(y_test)\n",
    "    #pred\n",
    "    #oos_pred.append(pred)\n",
    "    #score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"\\nFold score : {}\".format(score))\n",
    "    print(\"\\n\\nnew\\n\\n\")\n",
    "    print(classification_report(actual_y,predicted_y,terget_names=terget_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2603911940591881, 0.9156626556293074]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_validation_loss = 0\n",
    "total_validation_accu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in kfold_validation_score_store:\n",
    "    total_validation_loss += k[0]\n",
    "    total_validation_accu += k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.184157101299595"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333189911084549"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_validation_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predections = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rounded_predections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,rounded_predections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  6],\n",
       "       [ 1, 55]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[:,:] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd= 0\n",
    "for i in pred2:\n",
    "    asd = asd + i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3691864364913532"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd/84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0963855421686747"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final, out of sample score (RMSE): 0.44881939454625097\n"
     ]
    }
   ],
   "source": [
    "#build the oos predection list and calculate the error\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write he cross-validated predection\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "\n",
    "oosDF = pd.concat([df,oos_y,oos_pred],axis=1)\n",
    "oosDF.to_csv(\"filename_write.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange,sin,pi\n",
    "import numpy as np\n",
    "\n",
    "t = arange(1e-5,5.0,0.00001)\n",
    "#t = arang(1.0,5.0,0.00001) #computer scientist\n",
    "#t = arang(0.0,1.0,0.00001) #Data scientist\n",
    "\n",
    "fig = figure(1,figsize=(12,10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t,np.log(t))\n",
    "ax1.set_ylim((-8,1.5))\n",
    "ax1.set_xlim((-0.1,2))\n",
    "ax1.set_ylabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_title(\"log(x)\")\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
